{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea17a6a8-5198-4443-ac2c-7f060f6a7858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Import Libraries and Load Data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8badd4e-b39c-4e18-9533-674ab49b32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global styles for better visualization\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f704024c-b19a-4a78-bd0a-d748c35896df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "customers = pd.read_csv(r\"C:\\Users\\roxna\\Downloads\\Data_Intern\\Customers.csv\")\n",
    "products = pd.read_csv(r\"C:\\Users\\roxna\\Downloads\\Data_Intern\\Products.csv\")\n",
    "transactions = pd.read_csv(r\"C:\\Users\\roxna\\Downloads\\Data_Intern\\Transactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42123701-6895-40fa-b4e0-25dc89ccc637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   CustomerID    200 non-null    object\n",
      " 1   CustomerName  200 non-null    object\n",
      " 2   Region        200 non-null    object\n",
      " 3   SignupDate    200 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 6.4+ KB\n",
      "None\n",
      "\n",
      "Products Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   ProductID    100 non-null    object \n",
      " 1   ProductName  100 non-null    object \n",
      " 2   Category     100 non-null    object \n",
      " 3   Price        100 non-null    float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 3.3+ KB\n",
      "None\n",
      "\n",
      "Transactions Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   TransactionID    1000 non-null   object \n",
      " 1   CustomerID       1000 non-null   object \n",
      " 2   ProductID        1000 non-null   object \n",
      " 3   TransactionDate  1000 non-null   object \n",
      " 4   Quantity         1000 non-null   int64  \n",
      " 5   TotalValue       1000 non-null   float64\n",
      " 6   Price            1000 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 54.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def display_info():\n",
    "    print(\"Customers Dataset Info:\")\n",
    "    print(customers.info())\n",
    "    print(\"\\nProducts Dataset Info:\")\n",
    "    print(products.info())\n",
    "    print(\"\\nTransactions Dataset Info:\")\n",
    "    print(transactions.info())\n",
    "\n",
    "display_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a19fb9f8-1fb7-4069-a339-09139f18845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Dataset Sample:\n",
      "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue  Price_x     CustomerName         Region  SignupDate  \\\n",
      "0      300.68   300.68   Andrea Jenkins         Europe  2022-12-03   \n",
      "1      300.68   300.68  Brittany Harvey           Asia  2024-09-04   \n",
      "2      300.68   300.68  Kathryn Stevens         Europe  2024-04-04   \n",
      "3      601.36   300.68  Travis Campbell  South America  2024-04-11   \n",
      "4      902.04   300.68    Timothy Perez         Europe  2022-03-15   \n",
      "\n",
      "                       ProductName     Category  Price_y  \n",
      "0  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "1  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "2  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "3  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "4  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n"
     ]
    }
   ],
   "source": [
    "# Merge datasets for comprehensive analysis\n",
    "merged_data = transactions.merge(customers, on=\"CustomerID\").merge(products, on=\"ProductID\")\n",
    "print(\"\\nMerged Dataset Sample:\")\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a013cbb-b0c5-4475-bb6b-ab02af4390bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      "TransactionID      0\n",
      "CustomerID         0\n",
      "ProductID          0\n",
      "TransactionDate    0\n",
      "Quantity           0\n",
      "TotalValue         0\n",
      "Price_x            0\n",
      "CustomerName       0\n",
      "Region             0\n",
      "SignupDate         0\n",
      "ProductName        0\n",
      "Category           0\n",
      "Price_y            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(merged_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58ecc254-6f11-4a3c-bd0b-b8ec1b93d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values for simplicity\n",
    "merged_data.dropna(inplace=True)\n",
    "# Convert date columns to datetime\n",
    "merged_data['TransactionDate'] = pd.to_datetime(merged_data['TransactionDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c68dbdb0-4827-414a-98d3-fa98856dfb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of churned customers: 185\n"
     ]
    }
   ],
   "source": [
    "# Churn analysis: Identify inactive customers\n",
    "recent_date = merged_data['TransactionDate'].max()\n",
    "merged_data['DaysSinceLastPurchase'] = (recent_date - merged_data['TransactionDate']).dt.days\n",
    "churn_threshold = 180  # Days since last purchase to define churn\n",
    "churned_customers = merged_data[merged_data['DaysSinceLastPurchase'] > churn_threshold]['CustomerID'].unique()\n",
    "print(f\"Number of churned customers: {len(churned_customers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "288db35e-bc9a-48bc-aea3-9eb1ba87a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Lookalike Model\n",
    "\n",
    "# Feature engineering for customer behavior analysis\n",
    "customer_features = merged_data.groupby(\"CustomerID\").agg({\n",
    "    \"TotalValue\": \"sum\",\n",
    "    \"Quantity\": \"sum\",\n",
    "    \"Price_x\": \"mean\",\n",
    "    \"DaysSinceLastPurchase\": \"min\"\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98b2225a-b079-4b05-bf0c-e6e237008200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(customer_features.iloc[:, 1:])\n",
    "# Compute similarity matrix\n",
    "similarity_matrix = cosine_similarity(scaled_features)\n",
    "# Generate lookalike recommendations\n",
    "lookalikes = {}\n",
    "for idx, customer_id in enumerate(customer_features[\"CustomerID\"]):\n",
    "    similarity_scores = list(enumerate(similarity_matrix[idx]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)[1:4]\n",
    "    lookalikes[customer_id] = [(customer_features.iloc[i[0]][\"CustomerID\"], i[1]) for i in similarity_scores]\n",
    "# Format lookalike data for CSV\n",
    "lookalike_data = []\n",
    "for cust_id, recommendations in lookalikes.items():\n",
    "    for rec_cust_id, score in recommendations:\n",
    "        lookalike_data.append([cust_id, rec_cust_id, score])\n",
    "\n",
    "lookalike_df = pd.DataFrame(lookalike_data, columns=[\"CustomerID\", \"SimilarCustomerID\", \"SimilarityScore\"])\n",
    "lookalike_df.to_csv(r\"C:\\Users\\roxna\\Downloads\\Data_Intern\\Lookalike.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
